{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7280d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c581e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing datasets\n",
    "#Data.csv\n",
    "datasets = pd.read_csv('Datasets/Data.csv')\n",
    "X = datasets.iloc[0:,:-1]\n",
    "Y = datasets.iloc[0:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1edfc771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling the missing data\n",
    "\n",
    "#from sklearn.preprocessing import Imputer  (Deprecated with v0.20.04)\n",
    "\n",
    "#solution\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
    "#Cannot acces the array directly \n",
    "# need iloc/loc to access dataframe.\n",
    "imputer = imputer.fit(X.iloc[ :, 1:3])\n",
    "X.iloc[:,1:3] = imputer.transform(X.iloc[:,1:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c382e171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country        Age        Salary\n",
      "0   France  44.000000  72000.000000\n",
      "1    Spain  27.000000  48000.000000\n",
      "2  Germany  30.000000  54000.000000\n",
      "3    Spain  38.000000  61000.000000\n",
      "4  Germany  40.000000  63777.777778\n",
      "5   France  35.000000  58000.000000\n",
      "6    Spain  38.777778  52000.000000\n",
      "7   France  48.000000  79000.000000\n",
      "8  Germany  50.000000  83000.000000\n",
      "9   France  37.000000  67000.000000\n",
      "0     No\n",
      "1    Yes\n",
      "2     No\n",
      "3     No\n",
      "4    Yes\n",
      "5    Yes\n",
      "6     No\n",
      "7    Yes\n",
      "8     No\n",
      "9    Yes\n",
      "Name: Purchased, dtype: object\n",
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 4.40000000e+01\n",
      "  7.20000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 2.70000000e+01\n",
      "  4.80000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 3.00000000e+01\n",
      "  5.40000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.80000000e+01\n",
      "  6.10000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 4.00000000e+01\n",
      "  6.37777778e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.50000000e+01\n",
      "  5.80000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.87777778e+01\n",
      "  5.20000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.80000000e+01\n",
      "  7.90000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 5.00000000e+01\n",
      "  8.30000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.70000000e+01\n",
      "  6.70000000e+04]]\n",
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Encoding categorical data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# categorical_features is removed , so we use columnTranformer for those data\n",
    "#labelencoder_X = LabelEncoder()\n",
    "#X.values[ : , 0] = labelencoder_X.fit_transform(X.values[: , 0])\n",
    "\n",
    "#onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "#X = onehotencoder.fit_transform(X).toarray()\n",
    "print(X)\n",
    "print(Y)\n",
    "ct = ColumnTransformer([('encoder', OneHotEncoder() ,[0])], remainder = 'passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(Y)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954f0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the datasets into training and test datasets\n",
    "#from sklearn.cross_validation import train_test_split \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9963f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff3fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
